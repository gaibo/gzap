class CashInstr(Instrument):
    """
    Cash instrument, derived from financial instrument
    Defined by: 1) extracting a price time-series from Instrument through column names
    """
    def __init__(self, ts_df, **super_kwargs):
        """
        :param ts_df: time-series DataFrame with time and value
        :param super_kwargs: kwargs for passing to superclass
        """
        super().__init__(ts_df, **super_kwargs)

:param tradestats: (optional) relevant trade statistics, etc. to be included; default empty DataFrame

# # TYVIX Vol Regimes
# test = pd.read_csv('Y:/Research/Research1/Gaibo/S&P Webinar Figures/3 - predictive signaling raw data.csv', index_col='Date', parse_dates=True)
# _, axleft = plt.subplots()
# make_lineplot(tyvix.price(), 'TYVIX', ax=axleft)
# make_regime(tyvix.vol_regime()[2], 'High Vol Regime', 'grey', 'Date', 'Index Level', 'TYVIX Vol Regimes', ax=axleft)
# make_regime(tyvix.vol_regime()[1], 'Low Vol Regime', 'white', 'Date', 'Index Level', 'TYVIX Vol Regimes', ax=axleft)
# # axleft.autoscale(enable=True, axis='x', tight=True)
# axleft.legend(loc=2, fontsize=13)
# axleft.set_ylabel('Volatility Index (%)', fontsize=16)
# axright = axleft.twinx()
# axright.plot(test['10YR - 2YR Yield'], label='10yr - 2yr Yield', color='C1')
# axright.legend(loc=1, fontsize=13)
# axright.set_ylabel('% (Annualized)', fontsize=16)
# axright.set_xlim('2016-01-01', '2019-09-03')
# # axleft.autoscale(enable=True, axis='x', tight=True)
# # axright.set_ylim(20, 115)
# axleft.set_title('TYVIX Vol Regimes', fontsize=16)
# axleft.set_xlabel('Date', fontsize=16)

creditvix_data = pd.read_csv('data/creditvix_pc_bp_missing_4_months.csv',
                             index_col='Date', parse_dates=True)

tuvix = pd.read_csv('data/tuvix_cme.csv', index_col='Date', parse_dates=True)
fvvix = pd.read_csv('data/fvvix_cme.csv', index_col='Date', parse_dates=True)
tyvix_cme = pd.read_csv('data/tyvix_cme.csv', index_col='Date', parse_dates=True)
usvix = pd.read_csv('data/usvix_cme.csv', index_col='Date', parse_dates=True)

ten_two_list_low = get_regime_data_list(tyvix_lows, test['10YR - 2YR Yield'])
combined_ten_two_low = combine_data_list(map(lambda df: df.pct_change(), ten_two_list_low))
ten_two_list_high = get_regime_data_list(tyvix_highs, test['10YR - 2YR Yield'])
combined_ten_two_high = combine_data_list(map(lambda df: df.pct_change(), ten_two_list_high))

# regime_10_2 = pd.DataFrame({'regime': tyvix_hl, '10-2': test['10YR - 2YR Yield']}).dropna()
# # Lows
# low_acc = pd.Series()
# for interval in tyvix_lows:
#     changes = regime_10_2['10-2'].loc[interval[0]:interval[1]].diff().dropna()
#     low_acc = low_acc.append(changes)
# low_acc.mean()
# # Highs
# high_acc = pd.Series()
# for interval in tyvix_highs:
#     changes = regime_10_2['10-2'].loc[interval[0]:interval[1]].diff().dropna()
#     high_acc = high_acc.append(changes)
# high_acc.mean()

cdx_ig = Index(bbg_data['IBOXUMAE CBBT Curncy', 'PX_LAST'], 'CDX NA IG')
itraxx_ie = Index(bbg_data['ITRXEBE CBBT Curncy', 'PX_LAST'], 'iTraxx EU Main')
itraxx_xo = Index(bbg_data['ITRXEXE CBBT Curncy', 'PX_LAST'], 'iTraxx EU Xover')
itraxx_fs = Index(bbg_data['ITRXESE CBBT Curncy', 'PX_LAST'], 'iTraxx EU SenFin')

scaled_cdx_ig = cdx_ig.loc[roll_dates_df['CDX IG'].iloc[-1]:]   # Start with just the current series

srvix_undl_rv = (srvix.underlying.price().rolling(252).apply(
                     lambda p_252: (p_252.diff()**2).mean()**0.5 * 252**0.5, raw=False)) * 100
srvix_undl_rv = srvix_undl_rv.shift(-252)

full_data = pd.read_csv('../data/price_index_data.csv', index_col='Date', parse_dates=True)
eurostoxx_data = pd.read_csv('../data/sx5e_data.csv', index_col='Date', parse_dates=True)
sptr_data = pd.read_csv('../data/sptr_vix_data.csv', index_col='Date', parse_dates=True)
agg_data = pd.read_csv('../data/agg_data.csv', index_col='Date', parse_dates=True)

import sys
sys.path.insert(0, '/Users/gaibo.zhang/PycharmProjects/analysis_package/utility/')

[truncd_spx, truncd_ty1] = share_dateindex([spx.price(), ty1.price()])
make_lineplot([truncd_spx/truncd_spx[0], truncd_ty1/truncd_ty1[0]],
              ['SPX cumulative return', 'TY1 cumulative return'],
              ['C0', 'C4'])

[truncd_spx, truncd_ty1] = share_dateindex([spx.price(), ty1.price()])
make_lineplot([truncd_spx/truncd_spx[0], truncd_ty1/truncd_ty1[0]],
              ['SPX cumulative return', 'TY1 cumulative return'])

[joined_x_data, joined_y_data] = share_dateindex([instr_x.price_return(),
                                                                  instr_y.price_return()])
                x = joined_x_data.values.reshape(-1, 1)
                y = joined_y_data.values
                model = LinearRegression(fit_intercept=False).fit(x, y)

color_dict = {frozenset({spx, vix}): 'C1', frozenset({spx, hyg}): 'C2', frozenset({spx, ief}): 'C3',
                  frozenset({spx, sx5e}): 'C4', frozenset({spx, agg}): 'C5',
                  frozenset({vix, hyg}): 'C1', frozenset({vix, ief}): 'C2', frozenset({vix, sx5e}): 'C3',
                  frozenset({vix, agg}): 'C4',
                  frozenset({hyg, ief}): 'C1', frozenset({hyg, sx5e}): 'C2', frozenset({hyg, agg}): 'C3',
                  frozenset({ief, sx5e}): 'C1', frozenset({ief, agg}): 'C2',
                  frozenset({sx5e, agg}): 'C1'}

calc_log_returns = lambda arr: np.log(arr[-1]/arr[0]) if len(arr)>1 else np.NaN

elif granularity == 'intraday':
if time_start != time_end:
    print("WARNING: only time_start parameter is used for intraday.")
intraday_day = truncd_levels.loc[time_start, time_start + ONE_DAY]
return intraday_day.resample(intraday_interval, label='right', closed='right').pad()
elif granularity == 'multiday':
# NOTE: still uncertain about how to do this
return truncd_levels.resample(multiday_interval).pad()


def log_returns(self, time_start=None, time_end=None,
                do_resample=False, resample_interval=pd.Timedelta(minutes=5)):
    """ Calculate log returns
    :param time_start: start of time-series to use
    :param time_end: end of time-series to use
    :param do_resample: set True to resample to the granularity of <resample_interval>
    :param resample_interval: only relevant if resampling
    :return: pd.Series with 'time' and 'value'
    """
    if time_start is None:
        time_start = self.levels.first_valid_index()
    if time_end is None:
        time_end = self.levels.last_valid_index()
    truncd_levels = self.levels.truncate(time_start, time_end)
    if not self.is_intraday or not do_resample:
        # Data is already regular (i.e. daily or fixed-interval intraday) -
        # avoid messing with business days, etc.
        return np.log(truncd_levels).diff()
    else:
        # Data is intraday and irregular - resample to get fixed intervals
        resampled_truncd_levels = \
            truncd_levels.resample(resample_interval,
                                   label='right', closed='right').pad()
        return np.log(resampled_truncd_levels).diff()

table = pd.concat([vix_prices.describe().iloc[0:1].astype(int),
                       vix_prices.describe().iloc[1:],
                       vix_pct_changes.describe().iloc[1:]*100])

def make_scatterplot(x_data, y_data, xlabel=None, ylabel=None, title=None, ax=None):
    # Prepare Figure and Axes
    if ax is None:
        fig, ax = plt.subplots()
    else:
        fig = None
    # Plot
    x_data.to_frame(x_data.name).join(y_data.to_frame(y_data.name))
    ax.scatter(x_data, y_data)
    ax.grid()
    ax.plot([0, 1], [0, x_data.corr(y_data)], 'k')
    # Set labels
    if xlabel:
        ax.set_xlabel(xlabel)
    if ylabel:
        ax.set_ylabel(ylabel)
    if title:
        ax.set_title(title)
    return fig, ax

def make_scatterplot(x_instr, y_instr, ax=None):
    # Prepare Figure and Axes
    if ax is None:
        fig, ax = plt.subplots()
    else:
        fig = None
    # Plot
    x_returns = x_instr.price_return(logarithmic=False)
    y_returns = y_instr.price_return(logarithmic=False)
    joined_data = x_returns.to_frame(x_instr.name).join(y_returns.to_frame(y_instr.name), how='inner')
    ax.scatter(joined_data[x_instr.name], joined_data[y_instr.name])
    ax.grid()
    corr_x_y = x_returns.corr(y_returns)
    x_min = x_returns.min()
    x_max = x_returns.max()
    ax.plot([x_min, x_max], [x_min*corr_x_y, x_max*corr_x_y], 'k')
    # Set labels
    ax.set_xlabel("{} % Change".format(x_instr.name))
    ax.set_ylabel("{} % Change".format(y_instr.name))
    ax.set_title("Daily Percent Change: {} vs {}".format(x_instr.name, y_instr.name))
    return fig, ax

ax.set_xlabel("{} % Change".format(x_instr.name))
    ax.set_ylabel("{} % Change".format(y_instr.name))
    ax.set_title("Daily Percent Change: {} vs {}".format(x_instr.name, y_instr.name))

joined_data = x_data.to_frame('x').join(y_data.to_frame('y'), how='inner').dropna()

# Execute organized commands to create desired analyses
